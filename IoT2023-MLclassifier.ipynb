{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52777f1d-a960-4b1a-9a67-54f6ebaba326",
   "metadata": {},
   "source": [
    "# Centralised Learning and Federated Learning on the CICIoT2023 dataset\n",
    "\n",
    "This notebook extends on the functionality of the CICIoT2023 example notebook, to account for improvement to the centralised training of all data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef491788-2e80-4cfc-a86b-556eb4624ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bf33f7-12e7-4f6e-958b-6b5b0f8b2fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = './Train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b341488c-b030-4d79-96ac-ef52166f4237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sets = [k for i, k in enumerate(os.listdir(DATASET_DIRECTORY)) if k.endswith('.csv') and i % 3 == 0]\n",
    "df_sets.sort()\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a56162-0884-446a-9e1d-0140f65cf498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "y_column = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d10ad-299a-4741-bed8-dfb6d0a0e6fd",
   "metadata": {},
   "source": [
    "# Create a new DataFrame that consists of all CSV data\n",
    "\n",
    "This is **memory intensive** as it will create a DataFrame with 36 million rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1a6b27-8cf7-4d07-b950-bea6217296ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:40<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# x values only\n",
    "\n",
    "df = []\n",
    "\n",
    "count = 0\n",
    "for train_set in tqdm(training_sets):\n",
    "    if count == 0:\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + train_set)[X_columns]\n",
    "    else:\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + train_set)[X_columns]\n",
    "        df = pd.concat([df, df_new], ignore_index=True)\n",
    "    count = count + 1\n",
    "    \n",
    "df.to_pickle('training_data-X_values.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8316e08-519f-4238-99e0-a8a6b7770a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:21<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# y values only\n",
    "\n",
    "y_df = []\n",
    "\n",
    "count = 0\n",
    "for train_set in tqdm(training_sets):\n",
    "    if count == 0:\n",
    "        y_df = pd.read_csv(DATASET_DIRECTORY + train_set)[y_column]\n",
    "    else:\n",
    "        y_df_new = pd.read_csv(DATASET_DIRECTORY + train_set)[y_column]\n",
    "        y_df = pd.concat([y_df, y_df_new], ignore_index=True)\n",
    "    count = count + 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db0b5c29-b0c6-4c0f-811b-4742e6abee1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_df.to_pickle('training_data-y_value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95c0bce-0698-4e23-b070-3701040ac4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:24<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "count = 0\n",
    "for train_set in tqdm(training_sets):\n",
    "    if count == 0:\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    else:\n",
    "        df_new = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "        df = pd.concat([df, df_new], ignore_index=True)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6873b-ece2-4e99-a5a0-bb1733024e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb73a9-e0e6-44b2-8ad5-291e42fc3f0c",
   "metadata": {},
   "source": [
    "# Save this output to a Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dafe71b-84f3-4dea-b906-a4fe31f31ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_pickle('training_data-new_copy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e20e73-8a11-4b2a-adad-2a40464b2416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./training_data-new_copy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7173212a-62f1-4fd9-8b88-e62341c9ee0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_df = pd.read_pickle('./training_data-y_value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc61f15-94c0-4ea8-b87b-d27fd4db3136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049029e-2158-40a2-93fe-710dd87aa908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819a842-d247-4b52-9e87-1d55b2d173e1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30fdf1-6d0c-4a1a-8cea-0a6ae53288f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scale the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae08745b-9b58-4fad-8754-7051afed7b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[X_columns] = scaler.fit_transform(df[X_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cda5d5-e359-47d2-89ca-9d6d19432fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f18dd-f569-4c67-a320-54f5a2d1360a",
   "metadata": {},
   "source": [
    "# Classification Problem (2-class, 8-class, or 34-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c225c6-a510-4652-bd04-2a6027743158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming individual_classifier...\n"
     ]
    }
   ],
   "source": [
    "binary_classifier = False\n",
    "group_classifier = False\n",
    "individual_classifier = True\n",
    "\n",
    "if group_classifier:\n",
    "    \n",
    "    dict_7classes = {}\n",
    "    dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "    dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "    dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "    dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "    dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "    dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "    dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "    dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "    dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "    dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "    dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "    dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "    dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "    dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "    dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "    dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "    dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "    dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "    dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "    dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "    dict_7classes['BenignTraffic'] = 'Benign'\n",
    "    dict_7classes['BrowserHijacking'] = 'Web'\n",
    "    dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "    dict_7classes['XSS'] = 'Web'\n",
    "    dict_7classes['Uploading_Attack'] = 'Web'\n",
    "    dict_7classes['SqlInjection'] = 'Web'\n",
    "    dict_7classes['CommandInjection'] = 'Web'\n",
    "    dict_7classes['DictionaryBruteForce'] = 'BruteForce'\n",
    "\n",
    "    new_y = [dict_7classes[k] for k in y_df]\n",
    "    y_df = new_y\n",
    "    \n",
    "elif binary_classifier:\n",
    "    dict_2classes = {}\n",
    "    dict_2classes['DDoS-RSTFINFlood'] = 'Attack'\n",
    "    dict_2classes['DDoS-PSHACK_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-SYN_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-UDP_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-TCP_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-ICMP_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-SynonymousIP_Flood'] = 'Attack'\n",
    "    dict_2classes['DDoS-ACK_Fragmentation'] = 'Attack'\n",
    "    dict_2classes['DDoS-UDP_Fragmentation'] = 'Attack'\n",
    "    dict_2classes['DDoS-ICMP_Fragmentation'] = 'Attack'\n",
    "    dict_2classes['DDoS-SlowLoris'] = 'Attack'\n",
    "    dict_2classes['DDoS-HTTP_Flood'] = 'Attack'\n",
    "    dict_2classes['DoS-UDP_Flood'] = 'Attack'\n",
    "    dict_2classes['DoS-SYN_Flood'] = 'Attack'\n",
    "    dict_2classes['DoS-TCP_Flood'] = 'Attack'\n",
    "    dict_2classes['DoS-HTTP_Flood'] = 'Attack'\n",
    "    dict_2classes['Mirai-greeth_flood'] = 'Attack'\n",
    "    dict_2classes['Mirai-greip_flood'] = 'Attack'\n",
    "    dict_2classes['Mirai-udpplain'] = 'Attack'\n",
    "    dict_2classes['Recon-PingSweep'] = 'Attack'\n",
    "    dict_2classes['Recon-OSScan'] = 'Attack'\n",
    "    dict_2classes['Recon-PortScan'] = 'Attack'\n",
    "    dict_2classes['VulnerabilityScan'] = 'Attack'\n",
    "    dict_2classes['Recon-HostDiscovery'] = 'Attack'\n",
    "    dict_2classes['DNS_Spoofing'] = 'Attack'\n",
    "    dict_2classes['MITM-ArpSpoofing'] = 'Attack'\n",
    "    dict_2classes['BenignTraffic'] = 'Benign'\n",
    "    dict_2classes['BrowserHijacking'] = 'Attack'\n",
    "    dict_2classes['Backdoor_Malware'] = 'Attack'\n",
    "    dict_2classes['XSS'] = 'Attack'\n",
    "    dict_2classes['Uploading_Attack'] = 'Attack'\n",
    "    dict_2classes['SqlInjection'] = 'Attack'\n",
    "    dict_2classes['CommandInjection'] = 'Attack'\n",
    "    dict_2classes['DictionaryBruteForce'] = 'Attack'\n",
    "\n",
    "    new_y = [dict_2classes[k] for k in y_df]\n",
    "    y_df = new_y\n",
    "else:\n",
    "    print (\"Assuming individual_classifier...\")\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913f8dc-0cf9-4d63-ba59-70d13e2b4bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc76b81-34a2-4db2-84e9-664f4ea99ecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Creation (LR, RF, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa0e12b-db0c-40ef-9582-0089f2c28421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "logreg = True\n",
    "perceptron = True\n",
    "adaboost = True\n",
    "random_forest = True\n",
    "mlp = True\n",
    "\n",
    "logreg_model_filename = \"./Models-34class/new-logreg-34class-model.pkl\"\n",
    "perceptron_model_filename = \"./Models-34class/new-perceptron-34class-model.pkl\"\n",
    "adaboost_model_filename = \"./Models-34class/new-adaboost-34class-model.pkl\"\n",
    "rf_model_filename = \"./Models-34class/new-rf-34class-model.pkl\"\n",
    "mlp_model_filename = \"./Models-2class/new-mlp-34class-model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d225216-be78-4f69-8691-e61b4127c5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if logreg:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(random_state=42)\n",
    "\n",
    "    print (datetime.now(), \" : Fit LR model...\")\n",
    "    model.fit(df[X_columns], y_df)\n",
    "    print (datetime.now(), \" : Fit LR model complete...\")\n",
    "    \n",
    "    with open(logreg_model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = {i:[] for i in range(1)}\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[0] = preds[0] + y_pred\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "    for k,v in preds.items():\n",
    "        y_pred = v\n",
    "        print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "        print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "        print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "        print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a99c42-1345-46d2-b67a-59a28acbfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perceptron:\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    model = Perceptron(random_state=42)\n",
    "\n",
    "    print (datetime.now(), \" : Fit Perceptron model...\")\n",
    "    model.fit(df[X_columns], y_df)\n",
    "    print (datetime.now(), \" : Fit Perceptron model complete...\")\n",
    "    \n",
    "    with open(perceptron_model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = {i:[] for i in range(1)}\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[0] = preds[0] + y_pred\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "    for k,v in preds.items():\n",
    "        y_pred = v\n",
    "        print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "        print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "        print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "        print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0224ce0-6ca6-42f3-92d8-f5c34a8d18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adaboost:\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "    print (datetime.now(), \" : Fit AdaBoost model...\")\n",
    "    model.fit(df[X_columns], y_df)\n",
    "    print (datetime.now(), \" : Fit AdaBoost model complete...\")\n",
    "    \n",
    "    with open(adaboost_model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = {i:[] for i in range(1)}\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[0] = preds[0] + y_pred\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "    for k,v in preds.items():\n",
    "        y_pred = v\n",
    "        print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "        print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "        print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "        print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8067586-1077-442e-bb31-80e578429bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08 00:41:05.387334  : Fit RF model...\n",
      "2024-01-08 01:11:14.377028  : Fit RF model complete...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.0\n",
      "recall_score:  0.0\n",
      "precision_score:  0.0\n",
      "f1_score:  0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0    0 ...    0    0    0]\n",
      " [  84    0   14 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [  36    0    6 ...    0    0    0]\n",
      " [1358    0    1 ...    0    0    0]\n",
      " [ 129    0   24 ...    0    0    0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if random_forest:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
    "\n",
    "    print (datetime.now(), \" : Fit RF model...\")\n",
    "    model.fit(df[X_columns], y_df)\n",
    "    print (datetime.now(), \" : Fit RF model complete...\")\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(rf_model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = {i:[] for i in range(1)}\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[0] = preds[0] + y_pred\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "    for k,v in preds.items():\n",
    "        y_pred = v\n",
    "        print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "        print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "        print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "        print('f1_score: ', f1_score(y_pred, y_test, average='macro'))\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print('Confusion Matrix:\\n', cm)\n",
    "        print('\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03eba0-df52-416e-bcd8-ebea1008c266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if mlp:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    model = MLPClassifier(random_state=42)\n",
    "    print (datetime.now(), \" : Fit MLP model...\")\n",
    "    model.fit(df[X_columns], y_df)\n",
    "    print (datetime.now(), \" : Fit MLP model complete...\")\n",
    "    \n",
    "    with open(mlp_model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    y_test = []\n",
    "    preds = {i:[] for i in range(1)}\n",
    "    for test_set in tqdm(test_sets):\n",
    "        d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "        d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "        if binary_classifier:\n",
    "            # binary classifier (2-class)\n",
    "            new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "\n",
    "        elif group_classifier:\n",
    "            # group classifier (8-class)\n",
    "            new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "            d_test[y_column] = new_y\n",
    "\n",
    "        else:\n",
    "            # individual_classifier\n",
    "            pass\n",
    "\n",
    "        y_test += list(d_test[y_column].values)\n",
    "\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        preds[0] = preds[0] + y_pred\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "    for k,v in preds.items():\n",
    "        y_pred = v\n",
    "        print('accuracy_score: ', accuracy_score(y_pred, y_test))\n",
    "        print('recall_score: ', recall_score(y_pred, y_test, average='macro'))\n",
    "        print('precision_score: ', precision_score(y_pred, y_test, average='macro'))\n",
    "        print('f1_score: ', f1_score(y_pred, y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad60e9f-cbbe-4174-94af-78add09ca3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    #d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "\n",
    "\n",
    "    y_test += list(d_test[y_column].values)\n",
    "\n",
    "    #y_pred = list(model.predict(d_test[X_columns]))\n",
    "    #preds[0] = preds[0] + y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d326c-be2a-42f5-acde-15edfd8c7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7afc3-6a97-4e23-9b11-cee77f4c357c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "* 43 minutes to complete LR for 34 class - 14 minutes for 8 class - 7 minutes 2class\n",
    "* 1 hour 56 minutes to complete RF for 34 class - 2 hours 21 for 8 class.\n",
    "* 2 hours 39 minutes to complete MLP for 34 class - over 5 hours for 8 class - \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
